--- a/kernel/sched_fair.c	2011-08-02 16:04:22.000000000 -0400
+++ b/kernel/sched_fair.c	2011-09-11 15:50:51.000000000 -0400
@@ -3253,9 +3253,10 @@
 		cpu_rq(cpu)->in_nohz_recently = 1;
 
 		if (!cpu_active(cpu)) {
-			if (atomic_read(&nohz.load_balancer) != cpu)
+                      if (atomic_read(&nohz.load_balancer) != cpu) {
+				cpumask_clear_cpu(cpu, nohz.cpu_mask);
 				return 0;
-
+			}
 			/*
 			 * If we are going offline and still the leader,
 			 * give up!
@@ -3263,6 +3264,8 @@
 			if (atomic_cmpxchg(&nohz.load_balancer, cpu, -1) != cpu)
 				BUG();
 
+			cpumask_clear_cpu(cpu, nohz.cpu_mask);
+
 			return 0;
 		}
 
--- a/arch/arm/mm/cache-v7.S	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mm/cache-v7.S	2011-09-11 15:50:51.000000000 -0400
@@ -161,15 +161,15 @@
  UNWIND(.fnstart		)
 	dcache_line_size r2, r3
 	sub	r3, r2, #1
-	bic	r0, r0, r3
+	bic	r12, r0, r3
 #ifdef CONFIG_SCORPION_Uni_45nm_BUG
 1:
- USER(	mcr	p15, 0, r0, c7, c11, 1	)	@ clean D line to PoU (DCCMVAU)
-	add	r0, r0, r2
-2:
-	cmp	r0, r1
+ USER(	mcr	p15, 0, r12, c7, c11, 1	)	@ clean D line to PoU (DCCMVAU)
+	add	r12, r12, r2
+	cmp	r12, r1
 	blo	1b
 	dsb
+3:
 	mov	r0, #0
 	mcr	p15, 0, r0, c7, c5, 0		@ invalidate I-Cache and BTB
 	dsb
@@ -177,13 +177,20 @@
 	mov	pc, lr
 #else
 1:
- USER(	mcr	p15, 0, r0, c7, c11, 1	)	@ clean D line to the point of unification
+ USER(	mcr	p15, 0, r12, c7, c11, 1	)	@ clean D line to the point of unification
+	add	r12, r12, r2
+	cmp	r12, r1
+	blo	1b
 	dsb
- USER(	mcr	p15, 0, r0, c7, c5, 1	)	@ invalidate I line
-	add	r0, r0, r2
+	icache_line_size r2, r3
+	sub	r3, r2, #1
+	bic	r12, r0, r3
 2:
-	cmp	r0, r1
-	blo	1b
+ USER(	mcr	p15, 0, r12, c7, c5, 1  )	@ invalidate I line
+	add	r12, r12, r2
+	cmp	r12, r1
+	blo	2b
+3:
 	mov	r0, #0
 #ifdef CONFIG_SMP
 	mcr	p15, 0, r0, c7, c1, 6		@ invalidate BTB Inner Shareable
@@ -200,10 +207,10 @@
  * isn't mapped, just try the next page.
  */
 9001:
-	mov	r0, r0, lsr #12
-	mov	r0, r0, lsl #12
-	add	r0, r0, #4096
-	b	2b
+	mov	r12, r12, lsr #12
+	mov	r12, r12, lsl #12
+	add	r12, r12, #4096
+	b	3b
  UNWIND(.fnend		)
 ENDPROC(v7_coherent_kern_range)
 ENDPROC(v7_coherent_user_range)
--- a/arch/arm/mm/proc-macros.S	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mm/proc-macros.S	2011-09-11 15:50:51.000000000 -0400
@@ -72,6 +72,16 @@
 	mov	\reg, \reg, lsl \tmp		@ actual cache line size
 	.endm
 
+/*
+ * icache_line_size - get the minimum I-cache line size from the CTR register
+ * on ARMv7.
+ */
+	.macro	icache_line_size, reg, tmp
+	mrc	p15, 0, \tmp, c0, c0, 1		@ read ctr
+	and	\tmp, \tmp, #0xf		@ cache line size encoding
+	mov	\reg, #4			@ bytes per word
+	mov	\reg, \reg, lsl \tmp		@ actual cache line size
+	.endm
 
 /*
  * Sanity check the PTE configuration for the code below - which makes
--- a/arch/arm/mach-msm/pm-8x60.c	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mach-msm/pm-8x60.c	2011-09-11 15:50:51.000000000 -0400
@@ -603,7 +603,6 @@
 struct msm_pm_device {
 	unsigned int cpu;
 #ifdef CONFIG_HOTPLUG_CPU
-	unsigned long saved_acpu_rate;
 	struct completion cpu_killed;
 	unsigned int warm_boot;
 #endif
@@ -724,7 +723,12 @@
 
 	avsdscr_setting = avs_get_avsdscr();
 	avs_disable();
-	saved_acpuclk_rate = acpuclk_power_collapse();
+
+	if (cpu_online(dev->cpu))
+		saved_acpuclk_rate = acpuclk_power_collapse();
+	else
+		saved_acpuclk_rate = 0;
+
 	if (MSM_PM_DEBUG_CLOCK & msm_pm_debug_mask)
 		pr_info("CPU%u: %s: change clock rate (old rate = %lu)\n",
 			dev->cpu, __func__, saved_acpuclk_rate);
@@ -1113,12 +1117,8 @@
 	flush_cache_all();
 
 	for (;;) {
-		if (allow[MSM_PM_SLEEP_MODE_POWER_COLLAPSE]) {
-			struct msm_pm_device *dev =
-				&__get_cpu_var(msm_pm_devices);
-			dev->saved_acpu_rate = acpuclk_get_rate(cpu);
+		if (allow[MSM_PM_SLEEP_MODE_POWER_COLLAPSE])
 			msm_pm_power_collapse(false);
-		}
 		else if (allow[MSM_PM_SLEEP_MODE_POWER_COLLAPSE_STANDALONE])
 			msm_pm_power_collapse_standalone(false);
 		else if (allow[MSM_PM_SLEEP_MODE_WAIT_FOR_INTERRUPT])
@@ -1147,15 +1147,6 @@
 	vfp_reinit();
 #endif
 
-	if (dev->saved_acpu_rate) {
-		ret = acpuclk_set_rate(dev->cpu,
-				dev->saved_acpu_rate,
-				SETRATE_PC);
-		if (ret)
-			pr_err("CPU%u: %s: failed clock rate restore(%lu)\n",
-			dev->cpu, __func__, dev->saved_acpu_rate);
-		dev->saved_acpu_rate = 0;
-	}
 	ret = msm_spm_set_low_power_mode(MSM_SPM_MODE_CLOCK_GATING, false);
 
 	return ret;
--- a/arch/arm/mach-msm/acpuclock.h	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mach-msm/acpuclock.h	2011-09-11 15:50:51.000000000 -0400
@@ -26,6 +26,7 @@
 	SETRATE_CPUFREQ = 0,
 	SETRATE_SWFI,
 	SETRATE_PC,
+	SETRATE_HOTPLUG,
 	SETRATE_INIT,
 };
 
--- a/drivers/cpufreq/Kconfig	2011-08-02 16:04:21.000000000 -0400
+++ b/drivers/cpufreq/Kconfig	2011-09-11 16:43:22.000000000 -0400
@@ -18,6 +18,11 @@
 config CPU_FREQ_TABLE
 	tristate
 
+config CPU_FREQ_OVERRIDE
+	bool "Enable CPU options override"
+	help
+	  Say Y here
+
 config CPU_FREQ_DEBUG
 	bool "Enable CPUfreq debugging"
 	help
--- a/drivers/cpufreq/Makefile	2011-08-02 16:04:21.000000000 -0400
+++ b/drivers/cpufreq/Makefile	2011-09-11 16:43:05.000000000 -0400
@@ -10,6 +10,7 @@
 obj-$(CONFIG_CPU_FREQ_GOV_ONDEMAND)	+= cpufreq_ondemand.o
 obj-$(CONFIG_CPU_FREQ_GOV_ONDEMAND_TICKLE)	+= cpufreq_ondemand_tickle.o
 obj-$(CONFIG_CPU_FREQ_GOV_CONSERVATIVE)	+= cpufreq_conservative.o
+obj-$(CONFIG_CPU_FREQ_OVERRIDE)		+= cpufreq_override.o
 
 # CPUfreq cross-arch helpers
 obj-$(CONFIG_CPU_FREQ_TABLE)		+= freq_table.o
--- a/arch/arm/mach-msm/board-tenderloin.c	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mach-msm/board-tenderloin.c	2011-08-17 19:55:15.000000000 -0400
@@ -402,7 +402,7 @@
 		.constraints = {
 			.valid_ops_mask = REGULATOR_CHANGE_VOLTAGE,
 			.min_uV = 840000,
-			.max_uV = 1250000,
+			.max_uV = 1600000,
 		},
 		.num_consumer_supplies = 1,
 		.consumer_supplies = &saw_s0_supply,
@@ -412,7 +412,7 @@
 		.constraints = {
 			.valid_ops_mask = REGULATOR_CHANGE_VOLTAGE,
 			.min_uV = 840000,
-			.max_uV = 1250000,
+			.max_uV = 1600000,
 		},
 		.num_consumer_supplies = 1,
 		.consumer_supplies = &saw_s1_supply,
@@ -3005,9 +3005,9 @@
 	RPM_VREG_INIT_LDO(PM8058_L24, 0, 1, 0, 1200000, 1200000, LDO150HMIN, 0),
 	RPM_VREG_INIT_LDO(PM8058_L25, 0, 1, 0, 1200000, 1200000, LDO150HMIN, 0),
 
-	RPM_VREG_INIT_SMPS(PM8058_S0, 0, 1, 1,  500000, 1250000,  SMPS_HMIN, 0,
+	RPM_VREG_INIT_SMPS(PM8058_S0, 0, 1, 1,  500000, 1600000,  SMPS_HMIN, 0,
 		RPM_VREG_FREQ_1p60),
-	RPM_VREG_INIT_SMPS(PM8058_S1, 0, 1, 1,  500000, 1250000,  SMPS_HMIN, 0,
+	RPM_VREG_INIT_SMPS(PM8058_S1, 0, 1, 1,  500000, 1600000,  SMPS_HMIN, 0,
 		RPM_VREG_FREQ_1p60),
 	RPM_VREG_INIT_SMPS(PM8058_S2, 0, 1, 0, 1200000, 1400000,  SMPS_HMIN,
 		RPM_VREG_PIN_CTRL_A0, RPM_VREG_FREQ_1p60),
--- a/arch/arm/mach-msm/acpuclock-8x60.c	2011-08-02 16:04:21.000000000 -0400
+++ b/arch/arm/mach-msm/acpuclock-8x60.c	2011-09-11 16:02:43.000000000 -0400
@@ -52,9 +52,9 @@
  * The PLL hardware is capable of 384MHz to 1536MHz. The L_VALs
  * used for calibration should respect these limits. */
 #define L_VAL_SCPLL_CAL_MIN	0x08 /* =  432 MHz with 27MHz source */
-#define L_VAL_SCPLL_CAL_MAX	0x1C /* = 1512 MHz with 27MHz source */
+#define L_VAL_SCPLL_CAL_MAX	0x22 /* = 1836 MHz with 27MHz source */
 
-#define MAX_VDD_SC		1250000 /* uV */
+#define MAX_VDD_SC		1600000 /* uV */
 #define MAX_AXI			 310500 /* KHz */
 #define SCPLL_LOW_VDD_FMAX	 594000 /* KHz */
 #define SCPLL_LOW_VDD		1000000 /* uV */
@@ -182,21 +182,21 @@
 static struct clkctl_l2_speed l2_freq_tbl_v2[] = {
 	[0]  = { MAX_AXI, 0, 0,    1000000, 1100000, 0},
 	[1]  = { 432000,  1, 0x08, 1000000, 1100000, 0},
-	[2]  = { 486000,  1, 0x09, 1000000, 1100000, 0},
-	[3]  = { 540000,  1, 0x0A, 1000000, 1100000, 0},
-	[4]  = { 594000,  1, 0x0B, 1000000, 1100000, 0},
-	[5]  = { 648000,  1, 0x0C, 1000000, 1100000, 1},
-	[6]  = { 702000,  1, 0x0D, 1100000, 1100000, 1},
-	[7]  = { 756000,  1, 0x0E, 1100000, 1100000, 1},
-	[8]  = { 810000,  1, 0x0F, 1100000, 1100000, 1},
-	[9]  = { 864000,  1, 0x10, 1100000, 1100000, 1},
-	[10] = { 918000,  1, 0x11, 1100000, 1100000, 2},
-	[11] = { 972000,  1, 0x12, 1100000, 1100000, 2},
-	[12] = {1026000,  1, 0x13, 1100000, 1100000, 2},
-	[13] = {1080000,  1, 0x14, 1100000, 1200000, 2},
-	[14] = {1134000,  1, 0x15, 1100000, 1200000, 2},
-	[15] = {1188000,  1, 0x16, 1200000, 1200000, 3},
-	[16] = {1404000,  1, 0x1A, 1200000, 1250000, 3},
+	[2]  = { 540000,  1, 0x0A, 1000000, 1100000, 0},
+	[3]  = { 648000,  1, 0x0C, 1000000, 1100000, 1},
+	[4]  = { 756000,  1, 0x0E, 1100000, 1100000, 1},
+	[5]  = { 864000,  1, 0x10, 1100000, 1100000, 1},
+	[6]  = { 918000,  1, 0x11, 1100000, 1100000, 2},
+	[7]  = { 972000,  1, 0x12, 1100000, 1100000, 2},
+	[8]  = {1026000,  1, 0x13, 1100000, 1100000, 2},
+	[9]  = {1080000,  1, 0x14, 1100000, 1200000, 2},
+	[10] = {1134000,  1, 0x15, 1100000, 1200000, 2},
+	[11] = {1188000,  1, 0x16, 1200000, 1200000, 3},
+	[12] = {1242000,  1, 0x17, 1200000, 1200000, 3},
+	[13] = {1350000,  1, 0x19, 1200000, 1250000, 3},
+	[14] = {1448000,  1, 0x1A, 1200000, 1250000, 3},
+	[15] = {1458000,  1, 0x1B, 1200000, 1250000, 3},
+	[16] = {1512000,  1, 0x1C, 1250000, 1300000, 3},
 };
 
 #define L2(x) (&l2_freq_tbl_v2[(x)])
@@ -207,21 +207,22 @@
   { {0, 0},  MAX_AXI, ACPU_AFAB,  1, 0, 0, 0,    L2(0),   875000, 0x03006000},
   { {1, 1},  384000,  ACPU_PLL_8, 3, 0, 0, 0,    L2(1),   875000, 0x03006000},
   { {1, 1},  432000,  ACPU_SCPLL, 0, 0, 1, 0x08, L2(1),   887500, 0x03006000},
-  { {1, 1},  486000,  ACPU_SCPLL, 0, 0, 1, 0x09, L2(2),   912500, 0x03006000},
-  { {1, 1},  540000,  ACPU_SCPLL, 0, 0, 1, 0x0A, L2(3),   925000, 0x03006000},
-  { {1, 1},  594000,  ACPU_SCPLL, 0, 0, 1, 0x0B, L2(4),   937500, 0x03006000},
-  { {1, 1},  648000,  ACPU_SCPLL, 0, 0, 1, 0x0C, L2(5),   950000, 0x03006000},
-  { {1, 1},  702000,  ACPU_SCPLL, 0, 0, 1, 0x0D, L2(6),   975000, 0x03006000},
-  { {1, 1},  756000,  ACPU_SCPLL, 0, 0, 1, 0x0E, L2(7),  1000000, 0x03006000},
-  { {1, 1},  810000,  ACPU_SCPLL, 0, 0, 1, 0x0F, L2(8),  1012500, 0x03006000},
-  { {1, 1},  864000,  ACPU_SCPLL, 0, 0, 1, 0x10, L2(9),  1037500, 0x03006000},
-  { {1, 1},  918000,  ACPU_SCPLL, 0, 0, 1, 0x11, L2(10), 1062500, 0x03006000},
-  { {1, 1},  972000,  ACPU_SCPLL, 0, 0, 1, 0x12, L2(11), 1087500, 0x03006000},
-  { {1, 1}, 1026000,  ACPU_SCPLL, 0, 0, 1, 0x13, L2(12), 1125000, 0x03006000},
-  { {1, 1}, 1080000,  ACPU_SCPLL, 0, 0, 1, 0x14, L2(13), 1137500, 0x03006000},
-  { {1, 1}, 1134000,  ACPU_SCPLL, 0, 0, 1, 0x15, L2(14), 1162500, 0x03006000},
-  { {1, 1}, 1188000,  ACPU_SCPLL, 0, 0, 1, 0x16, L2(15), 1187500, 0x03006000},
-  { {1, 1}, 1512000,  ACPU_SCPLL, 0, 0, 1, 0x1C, L2(16), 1250000, 0x03006000},
+  { {1, 1},  540000,  ACPU_SCPLL, 0, 0, 1, 0x0A, L2(2),   925000, 0x03006000},
+  { {1, 1},  648000,  ACPU_SCPLL, 0, 0, 1, 0x0C, L2(3),   950000, 0x03006000},
+  { {1, 1},  756000,  ACPU_SCPLL, 0, 0, 1, 0x0E, L2(4),  1000000, 0x03006000},
+  { {1, 1},  864000,  ACPU_SCPLL, 0, 0, 1, 0x10, L2(5),  1037500, 0x03006000},
+  { {1, 1},  918000,  ACPU_SCPLL, 0, 0, 1, 0x11, L2(6),  1062500, 0x03006000},
+  { {1, 1},  972000,  ACPU_SCPLL, 0, 0, 1, 0x12, L2(7),  1087500, 0x03006000},
+  { {1, 1}, 1026000,  ACPU_SCPLL, 0, 0, 1, 0x13, L2(8),  1125000, 0x03006000},
+  { {1, 1}, 1080000,  ACPU_SCPLL, 0, 0, 1, 0x14, L2(9),  1137500, 0x03006000},
+  { {1, 1}, 1134000,  ACPU_SCPLL, 0, 0, 1, 0x15, L2(10), 1162500, 0x03006000},
+  { {1, 1}, 1188000,  ACPU_SCPLL, 0, 0, 1, 0x16, L2(11), 1187500, 0x03006000},
+  { {1, 1}, 1242000,  ACPU_SCPLL, 0, 0, 1, 0x17, L2(12), 1190000, 0x03006000},
+  { {1, 1}, 1350000,  ACPU_SCPLL, 0, 0, 1, 0x19, L2(13), 1195000, 0x03006000},
+  { {1, 1}, 1458000,  ACPU_SCPLL, 0, 0, 1, 0x1B, L2(14), 1200000, 0x03006000},
+  { {1, 1}, 1512000,  ACPU_SCPLL, 0, 0, 1, 0x1C, L2(15), 1250000, 0x03006000},
+  { {1, 1}, 1728000,  ACPU_SCPLL, 0, 0, 1, 0x20, L2(16), 1350000, 0x03006000},
+  { {1, 1}, 1836000,  ACPU_SCPLL, 0, 0, 1, 0x22, L2(16), 1450000, 0x03006000},
   { {0, 0}, 0 },
 };
 /* acpu_freq_tbl row to use when reconfiguring SC/L2 PLLs. */
@@ -231,6 +232,31 @@
 static struct clkctl_l2_speed *l2_freq_tbl;
 static unsigned int l2_freq_tbl_size;
 
+void acpuclk_get_voltages(unsigned int acpu_freq_vlt_tbl[])
+{
+	int i=0;
+	struct clkctl_acpu_speed *f;
+
+	for (f = acpu_freq_tbl_v2; f->acpuclk_khz != 0; f++) {
+		acpu_freq_vlt_tbl[i] = f->vdd_sc;
+		i++;
+	}
+
+}
+EXPORT_SYMBOL(acpuclk_get_voltages);
+
+void acpuclk_set_voltages(unsigned int acpu_freq_vlt_tbl[])
+{
+        int i=0;
+        struct clkctl_acpu_speed *f;
+
+	for (f = acpu_freq_tbl_v2; f->acpuclk_khz != 0; f++) {
+		f->vdd_sc = acpu_freq_vlt_tbl[i];
+		i++;
+	}
+}
+EXPORT_SYMBOL(acpuclk_set_voltages);
+
 unsigned long acpuclk_get_rate(int cpu)
 {
 	return drv_state.current_speed[cpu]->acpuclk_khz;
@@ -394,7 +420,7 @@
 		return;
 	}
 
-	/* Update bandwidth if requst has changed. */
+	/* Update bandwidth if requst has changed. This may sleep. */
 	ret = msm_bus_scale_client_update_request(bus_perf_client, bw);
 	if (ret)
 		pr_err("%s: bandwidth request failed (%d)\n", __func__, ret);
@@ -404,7 +430,7 @@
 
 /* Apply any per-cpu voltage increases. */
 static int increase_vdd(int cpu, unsigned int vdd_sc, unsigned int vdd_mem,
-			unsigned int vdd_dig)
+			unsigned int vdd_dig, enum setrate_reason reason)
 {
 	int rc = 0;
 
@@ -427,6 +453,13 @@
 		return rc;
 	}
 
+	 /* Don't update the Scorpion voltage in the hotplug path.  It should
+	  * already be correct.  Attempting to set it is bad because we don't
+	  * know what CPU we are running on at this point, but the Scorpion
+	  * regulator API requires we call it from the affected CPU.  */
+	if (reason == SETRATE_HOTPLUG)
+		return rc;
+
 	/* Update per-core Scorpion voltage. */
 	rc = regulator_set_voltage(regulator_sc[cpu], vdd_sc, MAX_VDD_SC);
 	if (rc) {
@@ -440,16 +473,21 @@
 
 /* Apply any per-cpu voltage decreases. */
 static void decrease_vdd(int cpu, unsigned int vdd_sc, unsigned int vdd_mem,
-			 unsigned int vdd_dig)
+			 unsigned int vdd_dig, enum setrate_reason reason)
 {
 	int ret;
 
-	/* Update per-core Scorpion voltage. */
-	ret = regulator_set_voltage(regulator_sc[cpu], vdd_sc, MAX_VDD_SC);
-	if (ret) {
-		pr_err("%s: vdd_sc (cpu%d) decrease failed (%d)\n",
-			__func__, cpu, ret);
-		return;
+	/* Update per-core Scorpion voltage. This must be called on the CPU
+	 * that's being affected. Don't do this in the hotplug remove path,
+	 * where the rail is off and we're executing on the other CPU. */
+	if (reason != SETRATE_HOTPLUG) {
+		ret = regulator_set_voltage(regulator_sc[cpu], vdd_sc,
+					    MAX_VDD_SC);
+		if (ret) {
+			pr_err("%s: vdd_sc (cpu%d) decrease failed (%d)\n",
+				__func__, cpu, ret);
+			return;
+		}
 	}
 
 	/* Decrease vdd_dig active-set vote. */
@@ -510,7 +548,7 @@
 		goto out;
 	}
 
-	if (reason == SETRATE_CPUFREQ)
+	if (reason == SETRATE_CPUFREQ || reason == SETRATE_HOTPLUG)
 		mutex_lock(&drv_state.lock);
 
 	strt_s = drv_state.current_speed[cpu];
@@ -549,9 +587,10 @@
 	vdd_dig = max(tgt_s->l2_level->vdd_dig, pll_vdd_dig);
 
 	/* Increase VDD levels if needed. */
-	if ((reason == SETRATE_CPUFREQ || reason == SETRATE_INIT)
+	if ((reason == SETRATE_CPUFREQ || reason == SETRATE_HOTPLUG
+	  || reason == SETRATE_INIT)
 			&& (tgt_s->acpuclk_khz > strt_s->acpuclk_khz)) {
-		rc = increase_vdd(cpu, tgt_s->vdd_sc, vdd_mem, vdd_dig);
+		rc = increase_vdd(cpu, tgt_s->vdd_sc, vdd_mem, vdd_dig, reason);
 		if (rc)
 			goto out;
 	}
@@ -581,7 +620,7 @@
 
 	/* Drop VDD levels if we can. */
 	if (tgt_s->acpuclk_khz < strt_s->acpuclk_khz)
-		decrease_vdd(cpu, tgt_s->vdd_sc, vdd_mem, vdd_dig);
+		decrease_vdd(cpu, tgt_s->vdd_sc, vdd_mem, vdd_dig, reason);
 
 	dprintk("ACPU%d speed change complete\n", cpu);
 
@@ -590,7 +629,7 @@
 		AVS_ENABLE(cpu, tgt_s->avsdscr_setting);
 
 out:
-	if (reason == SETRATE_CPUFREQ)
+	if (reason == SETRATE_CPUFREQ || reason == SETRATE_HOTPLUG)
 		mutex_unlock(&drv_state.lock);
 	return rc;
 }
@@ -749,37 +788,38 @@
 static void __init cpufreq_table_init(void) {}
 #endif
 
-static unsigned int __init select_freq_plan(void)
-{
-	uint32_t speed_bin, max_khz;
-	struct clkctl_acpu_speed *f;
-
-	acpu_freq_tbl = acpu_freq_tbl_v2;
-	l2_freq_tbl = l2_freq_tbl_v2;
-	l2_freq_tbl_size = ARRAY_SIZE(l2_freq_tbl_v2);
-
-	speed_bin = readl(QFPROM_SPEED_BIN_PRI) & 0xF;
-	if (speed_bin == 0x1)
-		max_khz = 1512000;
-	else
-		max_khz = 1188000;
-
-	/* Truncate the table based to max_khz. */
-	for (f = acpu_freq_tbl; f->acpuclk_khz != 0; f++) {
-		if (f->acpuclk_khz > max_khz) {
-			f->acpuclk_khz = 0;
-			break;
-		}
+#define HOT_UNPLUG_KHZ MAX_AXI
+static int __cpuinit acpuclock_cpu_callback(struct notifier_block *nfb,
+					  unsigned long action, void *hcpu)
+{
+	static int prev_khz[NR_CPUS];
+	int cpu = (int)hcpu;
+
+	switch (action) {
+	case CPU_DEAD:
+		    prev_khz[cpu] = acpuclk_get_rate(cpu);
+		    /* Fall through. */
+	case CPU_UP_CANCELED:
+		    acpuclk_set_rate(cpu, HOT_UNPLUG_KHZ, SETRATE_HOTPLUG);
+		    break;
+	case CPU_UP_PREPARE:
+		    if (WARN_ON(!prev_khz[cpu]))
+				  prev_khz[cpu] = acpu_freq_tbl->acpuclk_khz;
+		    acpuclk_set_rate(cpu, prev_khz[cpu], SETRATE_HOTPLUG);
+		    break;
+	default:
+		    break;
 	}
-	f--;
-	pr_info("Max ACPU freq: %u KHz\n", f->acpuclk_khz);
 
-	return f->acpuclk_khz;
+	return NOTIFY_OK;
 }
 
+static struct notifier_block __cpuinitdata acpuclock_cpu_notifier = {
+	.notifier_call = acpuclock_cpu_callback,
+};
+
 void __init msm_acpu_clock_init(struct msm_acpu_clock_platform_data *clkdata)
 {
-	unsigned int max_cpu_khz;
 	int cpu;
 
 	mutex_init(&drv_state.lock);
@@ -788,7 +828,10 @@
 	drv_state.vdd_switch_time_us = clkdata->vdd_switch_time_us;
 
 	/* Configure hardware. */
-	max_cpu_khz = select_freq_plan();
+	acpu_freq_tbl = acpu_freq_tbl_v2;
+	l2_freq_tbl = l2_freq_tbl_v2;
+	l2_freq_tbl_size = ARRAY_SIZE(l2_freq_tbl_v2);
+
 	unselect_scplls();
 	scpll_set_refs();
 	for_each_possible_cpu(cpu)
@@ -799,7 +842,8 @@
 
 	/* Improve boot time by ramping up CPUs immediately. */
 	for_each_online_cpu(cpu)
-		acpuclk_set_rate(cpu, max_cpu_khz, SETRATE_INIT);
+		acpuclk_set_rate(cpu, 1188000, SETRATE_INIT);
 
 	cpufreq_table_init();
+	register_hotcpu_notifier(&acpuclock_cpu_notifier);
 }
--- a/drivers/base/cpu.c	2010-08-01 18:11:14.000000000 -0400
+++ b/drivers/base/cpu.c	2011-08-27 17:02:58.000000000 -0400
@@ -14,6 +14,8 @@
 
 #include "base.h"
 
+bool cpufreq_override_tm(void);
+
 static struct sysdev_class_attribute *cpu_sysdev_class_attrs[];
 
 struct sysdev_class cpu_sysdev_class = {
@@ -42,9 +44,13 @@
 	cpu_hotplug_driver_lock();
 	switch (buf[0]) {
 	case '0':
-		ret = cpu_down(cpu->sysdev.id);
-		if (!ret)
-			kobject_uevent(&dev->kobj, KOBJ_OFFLINE);
+		if(!cpufreq_override_tm()) {
+			ret = cpu_down(cpu->sysdev.id);
+			if (!ret)
+				kobject_uevent(&dev->kobj, KOBJ_OFFLINE);
+		}
+		else
+			ret = 0;
 		break;
 	case '1':
 		ret = cpu_up(cpu->sysdev.id);
--- a/drivers/video/msm_pe/msm_fb.c	2011-08-02 16:04:22.000000000 -0400
+++ b/drivers/video/msm_pe/msm_fb.c	2011-08-29 19:03:00.000000000 -0400
@@ -51,6 +51,8 @@
 #include "mdp.h"
 #include "mdp4.h"
 
+void cpufreq_override_lcd_state(bool state);
+
 #ifdef CONFIG_FB_MSM_LOGO
 #define INIT_IMAGE_FILE "/initlogo.rle"
 extern int load_565rle_image(char *filename);
@@ -354,6 +356,9 @@
 			//fb_set_suspend(mfd->fbi[0], FBINFO_STATE_RUNNING);
 
 			mfd->suspended = false;
+
+                        cpufreq_override_lcd_state(1);
+
 		}
 
 	}
@@ -374,6 +379,9 @@
 				//fb_set_suspend(mfd->fbi[0], FBINFO_STATE_SUSPENDED);
 				mfd->pdev->dev.power.power_state = PMSG_SUSPEND;
 				mfd->suspended = true;
+
+                        	cpufreq_override_lcd_state(0);
+
 			}
 		}
 
--- a/drivers/cpufreq/cpufreq_override.c	1969-12-31 19:00:00.000000000 -0500
+++ b/drivers/cpufreq/cpufreq_override.c	2011-09-11 15:44:47.000000000 -0400
@@ -0,0 +1,287 @@
+/*
+ *  drivers/cpufreq/cpufreq_override.c
+ *
+ *      Marco Benton <marco@unixpsycho.com>.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/sysdev.h>
+#include <linux/cpu.h>
+#include <linux/sysfs.h>
+#include <linux/cpufreq.h>
+#include <linux/jiffies.h>
+#include <linux/kobject.h>
+#include <linux/string.h>
+#include <linux/kernel_stat.h>
+
+// Voltage min
+#define VDD_MIN 800000
+
+// Voltage max
+#define VDD_MAX 1600000
+
+// Freq count
+#define NR_FREQS 20
+
+// Turbo Mode default state (both CPUs online all the time)
+#define TURBOMODE 1
+
+// Power saving mode
+#define POWERSAVE 0
+
+void acpuclk_get_voltages(unsigned int acpu_freq_vlt_tbl[]);
+void acpuclk_set_voltages(unsigned int acpu_freq_vlt_tbl[]);
+
+bool turbomode = TURBOMODE;
+bool lcd_state = 1;
+bool power_save = POWERSAVE;
+
+static cputime64_t prev_cpu_wall = 0, prev_cpu_idle = 0;
+static unsigned int last_load = 0;
+
+static inline cputime64_t get_cpu_idle_time(unsigned int cpu)
+{
+        cputime64_t idle_time;
+        cputime64_t cur_jiffies;
+        cputime64_t busy_time;
+
+        cur_jiffies = jiffies64_to_cputime64(get_jiffies_64());
+        busy_time = cputime64_add(kstat_cpu(cpu).cpustat.user,
+                                  kstat_cpu(cpu).cpustat.system);
+
+        busy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.irq);
+        busy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.softirq);
+        busy_time = cputime64_add(busy_time, kstat_cpu(cpu).cpustat.steal);
+
+        idle_time = cputime64_sub(cur_jiffies, busy_time);
+        return idle_time;
+}
+
+static inline unsigned int cur_load(void)
+{
+        unsigned int tmp_idle_ticks, idle_ticks, total_ticks, load = 0, ret = 0;
+        cputime64_t total_idle_ticks, cur_jiffies;
+
+        idle_ticks = UINT_MAX;
+        cur_jiffies = jiffies64_to_cputime64(get_jiffies_64());
+        total_ticks = (unsigned int)cputime64_sub(cur_jiffies, prev_cpu_wall);
+        prev_cpu_wall = get_jiffies_64();
+
+        if (!total_ticks)
+                goto out;
+
+        total_idle_ticks = get_cpu_idle_time(0);
+        tmp_idle_ticks = (unsigned int)cputime64_sub(total_idle_ticks,
+                                                     prev_cpu_idle);
+        prev_cpu_idle = total_idle_ticks;
+
+        if (tmp_idle_ticks < idle_ticks)
+                idle_ticks = tmp_idle_ticks;
+        if (likely(total_ticks > idle_ticks))
+                load = (100 * (total_ticks - idle_ticks)) / total_ticks;
+
+        if (!last_load)
+                goto out;
+
+	ret = load;
+
+out:
+        last_load = load;
+
+	return ret;
+}
+
+bool cpufreq_override_tm(void)
+{
+	unsigned int load = 0;
+	bool ret = 0;
+
+	// TODO
+	if(power_save) {
+		if(!lcd_state) ret=0;
+		else {
+			load=cur_load();
+			ret = (load < 21) ? 0 : 1;
+		}
+	}
+	else {
+		ret = turbomode;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(cpufreq_override_tm);
+
+void cpufreq_override_lcd_state(bool state)
+{
+	struct sys_device *dev = get_cpu_sysdev(1);
+
+	lcd_state = state;
+	printk("override: lcd state=%u\n",state);
+
+	// If screen is off, take cpu offline if in power save mode
+	if(power_save && !lcd_state) {
+		cpu_hotplug_driver_lock();
+		if(!cpu_down(1)) kobject_uevent(&dev->kobj, KOBJ_OFFLINE);
+		cpu_hotplug_driver_unlock();
+	}
+	// force CPU online if not in power save mode
+	if(!power_save && lcd_state) {
+		cpu_hotplug_driver_lock();
+		if(!cpu_up(1)) kobject_uevent(&dev->kobj, KOBJ_ONLINE);
+		cpu_hotplug_driver_unlock();
+	}
+}
+EXPORT_SYMBOL(cpufreq_override_lcd_state);
+
+static ssize_t show_vdd_max(struct kobject *kobj, struct attribute *attr,
+				char *buf)
+{
+        return sprintf(buf, "%u\n", VDD_MAX);
+}
+
+static ssize_t show_vdd_min(struct kobject *kobj, struct attribute *attr,
+				char *buf)
+{
+        return sprintf(buf, "%u\n", VDD_MIN);
+}
+
+static ssize_t show_vdd(struct kobject *kobj, struct attribute *attr, char *buf)
+{
+	unsigned int i, acpu_freq_vlt_tbl[NR_FREQS];
+	char tmp[200];
+
+	acpuclk_get_voltages(acpu_freq_vlt_tbl);
+
+	strcpy(buf,"");
+
+	for(i=0 ; i < NR_FREQS ; ++i) {
+		sprintf(tmp,"%u ",acpu_freq_vlt_tbl[i]);
+		strcat(buf,tmp);
+	}
+
+	strcpy(tmp,buf);
+
+	return sprintf(buf,"%s\n",tmp);
+}
+
+static ssize_t store_vdd(struct kobject *a, struct attribute *b,
+				const char *buf, size_t count)
+{
+	unsigned int i = 0, acpu_freq_vlt_tbl[NR_FREQS];
+	unsigned int *c = acpu_freq_vlt_tbl;
+
+	// FIXME
+	i = sscanf(buf, "%u %u %u %u %u %u %u %u %u %u %u %u %u %u %u %u %u %u "
+			"%u %u",
+				&c[0],&c[1],&c[2],&c[3],&c[4],&c[5],&c[6],
+				&c[7],&c[8],&c[9],&c[10],&c[11],&c[12],&c[13],
+				&c[14],&c[15],&c[16],&c[17],&c[18],
+				&c[19]);
+	if(i != NR_FREQS)
+		printk("override: store_vdd invalid\n");
+	else {
+		for(i=0; i < NR_FREQS ; ++i)
+			if(acpu_freq_vlt_tbl[i] < VDD_MIN || 
+					acpu_freq_vlt_tbl[i] > VDD_MAX) {
+				printk("override: store_vdd vdd %u invalid\n",
+					acpu_freq_vlt_tbl[i]);
+				break;
+			}
+
+		if(i == NR_FREQS) acpuclk_set_voltages(acpu_freq_vlt_tbl);
+	}
+
+	return count;
+}
+
+static ssize_t show_turbo_mode(struct kobject *kobj, struct attribute *attr,
+				char *buf)
+{
+	return sprintf(buf,"%u\n",turbomode);
+}
+
+static ssize_t store_turbo_mode(struct kobject *a, struct attribute *b,
+				const char *buf, size_t count)
+{
+	unsigned int tmp;
+
+	if(sscanf(buf, "%u", &tmp) == 1)
+		turbomode = (tmp != 0 && tmp != 1) ? turbomode : tmp;
+	else
+		printk("override: invalid turbo_mode\n");
+
+	return count;
+}
+
+static ssize_t show_power_saver(struct kobject *kobj, struct attribute *attr,
+                                char *buf)
+{
+        return sprintf(buf,"%u\n",power_save);
+}
+
+static ssize_t store_power_saver(struct kobject *a, struct attribute *b,
+                                const char *buf, size_t count)
+{
+        unsigned int tmp;
+
+        if(sscanf(buf, "%u", &tmp) == 1)
+                power_save = (tmp != 0 && tmp != 1) ? power_save : tmp;
+        else
+                printk("override: invalid power save mode\n");
+
+        return count;
+}
+
+define_one_global_ro(vdd_min);
+define_one_global_ro(vdd_max);
+define_one_global_rw(vdd);
+define_one_global_rw(turbo_mode);
+define_one_global_rw(power_saver);
+
+static struct attribute *default_attrs[] = {
+        &vdd.attr,
+        &turbo_mode.attr,
+        &power_saver.attr,
+        &vdd_min.attr,
+        &vdd_max.attr,
+        NULL
+};
+
+static struct attribute_group override_attr_group = {
+        .attrs = default_attrs,
+        .name = "override"
+};
+
+static int __init cpufreq_override_driver_init(void)
+{
+        printk("override: initialized!\n");
+	return sysfs_create_group(cpufreq_global_kobject,&override_attr_group);
+}
+
+static void __exit cpufreq_override_driver_exit(void)
+{
+        sysfs_remove_group(cpufreq_global_kobject, &override_attr_group);
+}
+
+MODULE_AUTHOR("marco@unixpsycho.com");
+MODULE_DESCRIPTION("'cpufreq_override' - A driver to do cool stuff ");
+MODULE_LICENSE("GPL");
+
+module_init(cpufreq_override_driver_init);
+module_exit(cpufreq_override_driver_exit);
+
